from urllib import request
import re

class Spider():
    '''熊猫平台爬取主播姓名和人气'''
    
    url = 'https://www.panda.tv/cate/dnf'
    # 尽量匹配离数据近，具有唯一属性并且是闭合标签的元素。
    root_pattern = '<div class="video-info">([\s\S]*?)</div>' #加上组可以去掉info标签，非贪婪。注意单双引号
    name_pattern = '<span class="video-nickname" title="([\S]+?)">'
    number_pattern = '<span class="video-number">([\s\S]*?)</span>'

    def __fetch_content(self):
        '''解析网页'''
        
        r = request.urlopen(Spider.url) #获取
        htmls = r.read()
        htmls = str(htmls, encoding='utf-8') #将bytes转成str
        return htmls

    def __analysis(self, htmls):
        '''拿到name和人数数据'''
        
        root_html = re.findall(Spider.root_pattern, htmls)
        anchors = []
        for html in root_html:
            name = re.findall(Spider.name_pattern, html)
            number = re.findall(Spider.number_pattern, html)
            anchor = {'name': name, 'number': number}
            anchors.append(anchor)
        return anchors

    def __refine(self, anchors):
        '''遍历并去空格'''
        
        l = lambda anchor:{
            'name':anchor['name'][0].strip(), #strip去字符串空格
            'number':anchor['number'][0]
        }
        return map(l, anchors)

    def __sort(self, anchors):
        # sorted排序,key根据number。reverse倒序（默认Flase）
        anchors = sorted(anchors, key=self.__sort_seed, reverse=True)
        return anchors

    def __sort_seed(self, anchor):
        '''将字符转成数字'''
        
        # 去掉‘人’，提取数字
        r = re.findall('\d*', anchor['number'])

        # 转成float
        number = float(r[0])

        # 找到‘万’乘10000
        if '万' in anchor['number']:
            number *= 10000

        # 返回number,而不是anchor['number']
        return number

    def __show(self, anchors):
        '''根据下标编序'''
        
        for rank in range(0, len(anchors)):
            print(str(rank + 1)
                  + ':' + anchors[rank]['name']
                  + '   ' + anchors[rank]['number'])

    def go(self):
        '''入口方法'''
        
        htmls = self.__fetch_content()
        anchors = self.__analysis(htmls)
        anchors = list(self.__refine(anchors))
        anchors = self.__sort(anchors)
        self.__show(anchors)


spider = Spider()
spider.go()
